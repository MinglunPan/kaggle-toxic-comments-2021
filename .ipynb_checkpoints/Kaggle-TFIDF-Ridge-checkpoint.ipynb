{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bedc38b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import re \n",
    "import scipy\n",
    "from scipy import sparse\n",
    "\n",
    "from IPython.display import display\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import time\n",
    "import scipy.optimize as optimize\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_colwidth=300\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e3e5ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilingual-toxic-comment-classification\r\n",
      "ruddit-jigsaw-dataset\r\n",
      "temporary\r\n",
      "toxic-comment-classification-challenge\r\n",
      "toxic-severity-rating\r\n",
      "unintended-bias-in-toxicity-classification\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbad7e0",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07b487cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/toxic-comment-classification-challenge/train.csv\")\n",
    "df_sub = pd.read_csv(\"data/toxic-severity-rating/comments_to_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75e5d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffList(new_list, base_list):\n",
    "    return list(set(new_list) - set(base_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e8e3f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightedSum(data, weight_dict):\n",
    "    return (data[weight_dict.keys()] * np.array(weight_dict)).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b28a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_target_dict = {'obscene': 0.16, 'toxic': 0.32, 'threat': 1.5,  'insult': 0.64, 'severe_toxic': 1.5, 'identity_hate': 1.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "49a4f73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          y\n",
       "0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0.0\n",
       "4       0.0\n",
       "...     ...\n",
       "159566  0.0\n",
       "159567  0.0\n",
       "159568  0.0\n",
       "159569  0.0\n",
       "159570  0.0\n",
       "\n",
       "[159571 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightedSum(df_train, weights_target_dict).to_frame('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48fdc006",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataSet:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def set_target(self, response_col = None, average_weights_dict = None, y_col = 'y'):\n",
    "        assert (response == None)^(average_weights_dict == None)\n",
    "        if average_weights_dict != None: \n",
    "            assert isinstance(average_weights_dict, dict)\n",
    "            self.data['y'] = weightedSum(self.data, weights_target_dict).to_frame('y')\n",
    "            self.y_col = 'y'\n",
    "        if response != None: \n",
    "            assert isinstance(response, str)\n",
    "            assert response_col in self.data.columns\n",
    "            self.data.rename(columns = {response_col:y_col}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7b4ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeHTMLTags(text):\n",
    "    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n",
    "    text = soup.get_text()\n",
    "    return text\n",
    "def removeURL(text):\n",
    "    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n",
    "    text = template.sub(r'', text)\n",
    "    return text\n",
    "def removeEmoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    return text\n",
    "def removeSpecialCharacters(text):\n",
    "    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text)\n",
    "    return text\n",
    "def removeExtraSpaces(text):\n",
    "    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n",
    "    return text #Remove Extra Spaces\n",
    "def removeBegingEndSpace(text):\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88869d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    '''\n",
    "    Cleans text into a basic form for NLP. Operations include the following:-\n",
    "    1. Remove special charecters like &, #, etc\n",
    "    2. Removes extra spaces\n",
    "    3. Removes embedded URL links\n",
    "    4. Removes HTML tags\n",
    "    5. Removes emojis\n",
    "    \n",
    "    text - Text piece to be cleaned.\n",
    "    '''\n",
    "    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n",
    "    text = template.sub(r'', text)\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n",
    "    only_text = soup.get_text()\n",
    "    text = only_text\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n",
    "    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n",
    "    text = text.strip() # remove spaces at the beginning and at the end of string\n",
    "\n",
    "    return text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
